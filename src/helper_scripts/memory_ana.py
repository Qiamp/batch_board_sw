"""
GNSS-IMU Fusion Memory Analysis Tool
=====================================

This script analyzes memory usage from CSV files generated by the GNSS-IMU fusion node.
It provides comprehensive visualization and statistics for memory consumption patterns.

Author: Auto-generated analysis tool
Usage: python3 memory_ana.py [--input_dir] [--output_dir]
python3 memory_ana.py --state_csv /path/to/state.csv --output_dir ./my_analysis
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import argparse
import os
import glob
from datetime import datetime
import seaborn as sns
from pathlib import Path
import warnings
import subprocess
import sys
from scipy import stats  # Add scipy import for CDF calculation

warnings.filterwarnings('ignore')

class MemoryAnalyzer:
    """Memory usage analyzer for GNSS-IMU fusion system"""
    
    def __init__(self, input_dir="/home/jay/batch_board/output", 
                 output_dir=None, trajectory_csv=None, state_csv=None, show_plots=True):
        self.input_dir = Path(input_dir)
        
        # If no output directory specified, use script directory
        if output_dir is None:
            script_dir = Path(__file__).parent
            self.output_dir = script_dir / "memory_analysis_results"
        else:
            self.output_dir = Path(output_dir)
        
        # Direct CSV file paths
        self.trajectory_csv_path = Path(trajectory_csv) if trajectory_csv else None
        self.state_csv_path = Path(state_csv) if state_csv else None
        
        # Display options
        self.show_plots = show_plots
        self.generated_plots = []  # Track generated plot files
            
        self.trajectory_data = None
        self.state_data = None
        
        # Create output directory if it doesn't exist
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Set up plotting style
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
    def load_csv_files(self):
        """Load trajectory and state CSV files"""
        print("Loading CSV files...")
        
        # Load trajectory CSV file
        if self.trajectory_csv_path and self.trajectory_csv_path.exists():
            # Use specified trajectory CSV file
            print(f"Loading specified trajectory file: {self.trajectory_csv_path}")
            try:
                self.trajectory_data = pd.read_csv(self.trajectory_csv_path)
                print(f"Loaded {len(self.trajectory_data)} trajectory records")
            except Exception as e:
                print(f"Error loading trajectory file: {e}")
        else:
            # Find trajectory CSV files in directory
            trajectory_files = list(self.input_dir.glob("gnss_imu_trajectory_*.csv"))
            if not trajectory_files:
                print(f"No trajectory CSV files found in {self.input_dir}")
            else:
                # Load the most recent trajectory file
                latest_traj_file = max(trajectory_files, key=lambda x: x.stat().st_mtime)
                print(f"Loading trajectory file: {latest_traj_file}")
                try:
                    self.trajectory_data = pd.read_csv(latest_traj_file)
                    print(f"Loaded {len(self.trajectory_data)} trajectory records")
                except Exception as e:
                    print(f"Error loading trajectory file: {e}")
        
        # Load state CSV file
        if self.state_csv_path and self.state_csv_path.exists():
            # Use specified state CSV file
            print(f"Loading specified state file: {self.state_csv_path}")
            try:
                self.state_data = pd.read_csv(self.state_csv_path)
                print(f"Loaded {len(self.state_data)} state records")
                
                # Convert timestamp to datetime
                self.state_data['datetime'] = pd.to_datetime(self.state_data['timestamp'], unit='s')
                return True
            except Exception as e:
                print(f"Error loading state file: {e}")
                return False
        else:
            # Find state CSV files in directory
            state_files = list(self.input_dir.glob("gnss_imu_state_*.csv"))
            if not state_files:
                print(f"No state CSV files found in {self.input_dir}")
                return False
            else:
                # Load the most recent state file
                latest_state_file = max(state_files, key=lambda x: x.stat().st_mtime)
                print(f"Loading state file: {latest_state_file}")
                try:
                    self.state_data = pd.read_csv(latest_state_file)
                    print(f"Loaded {len(self.state_data)} state records")
                    
                    # Convert timestamp to datetime
                    self.state_data['datetime'] = pd.to_datetime(self.state_data['timestamp'], unit='s')
                    return True
                except Exception as e:
                    print(f"Error loading state file: {e}")
                    return False
    
    def analyze_memory_statistics(self):
        """Calculate comprehensive memory statistics"""
        if self.state_data is None:
            print("No state data available for analysis")
            return
        
        print("\n" + "="*60)
        print("MEMORY USAGE STATISTICS")
        print("="*60)
        
        # Basic statistics
        mem_cols = ['virtual_memory_mb', 'physical_memory_mb', 'peak_memory_mb']
        
        for col in mem_cols:
            if col in self.state_data.columns:
                data = self.state_data[col].dropna()
                if len(data) > 0:
                    print(f"\n{col.upper().replace('_', ' ')}:")
                    print(f"  Min: {data.min():.2f} MB")
                    print(f"  Max: {data.max():.2f} MB")
                    print(f"  Mean: {data.mean():.2f} MB")
                    print(f"  Std: {data.std():.2f} MB")
        
        # Memory growth analysis
        if 'memory_growth_mb' in self.state_data.columns:
            growth_data = self.state_data['memory_growth_mb'].dropna()
            positive_growth = growth_data[growth_data > 0]
            negative_growth = growth_data[growth_data < 0]
            
            print(f"\nMEMORY GROWTH ANALYSIS:")
            print(f"  Total records: {len(growth_data)}")
            print(f"  Positive growth events: {len(positive_growth)}")
            print(f"  Negative growth events: {len(negative_growth)}")
            print(f"  Average growth per step: {growth_data.mean():.4f} MB")
            print(f"  Max single growth: {growth_data.max():.2f} MB")
            print(f"  Max single reduction: {growth_data.min():.2f} MB")
        
        # Factor efficiency analysis
        factor_cols = ['total_gnss_pos_factors', 'total_gnss_vel_factors', 
                      'total_imu_factors', 'total_bias_factors', 'total_factors']
        
        if all(col in self.state_data.columns for col in factor_cols):
            latest_row = self.state_data.iloc[-1]
            latest_memory = latest_row['physical_memory_mb']
            
            print(f"\nFACTOR EFFICIENCY ANALYSIS:")
            for col in factor_cols[:-1]:  # Exclude total_factors
                factor_count = latest_row[col]
                if factor_count > 0:
                    efficiency = latest_memory / factor_count
                    print(f"  {col}: {factor_count} factors, {efficiency:.3f} MB/factor")
            
            total_factors = latest_row['total_factors']
            if total_factors > 0:
                overall_efficiency = latest_memory / total_factors
                print(f"  Overall: {total_factors} total factors, {overall_efficiency:.3f} MB/factor")
        
        # Performance correlation
        if 'optimization_time_ms' in self.state_data.columns:
            opt_time = self.state_data['optimization_time_ms'].dropna()
            phys_mem = self.state_data['physical_memory_mb'].dropna()
            
            if len(opt_time) > 1 and len(phys_mem) > 1:
                correlation = np.corrcoef(opt_time, phys_mem[:len(opt_time)])[0,1]
                print(f"\nPERFORMANCE CORRELATION:")
                print(f"  Memory vs Optimization Time correlation: {correlation:.3f}")
    
    def plot_memory_timeline(self):
        """Plot memory usage over time"""
        if self.state_data is None:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Memory Usage Timeline Analysis', fontsize=16, fontweight='bold')
        
        # Plot 1: All memory types over time
        ax1 = axes[0, 0]
        if 'virtual_memory_mb' in self.state_data.columns:
            ax1.plot(self.state_data['datetime'], self.state_data['virtual_memory_mb'], 
                    label='Virtual Memory', linewidth=2, alpha=0.8)
        if 'physical_memory_mb' in self.state_data.columns:
            ax1.plot(self.state_data['datetime'], self.state_data['physical_memory_mb'], 
                    label='Physical Memory', linewidth=2, alpha=0.8)
        if 'peak_memory_mb' in self.state_data.columns:
            ax1.plot(self.state_data['datetime'], self.state_data['peak_memory_mb'], 
                    label='Peak Memory', linewidth=2, alpha=0.8)
        
        ax1.set_title('Memory Usage Over Time')
        ax1.set_xlabel('Time')
        ax1.set_ylabel('Memory (MB)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Plot 2: Memory growth rate
        ax2 = axes[0, 1]
        if 'memory_growth_mb' in self.state_data.columns:
            growth_data = self.state_data['memory_growth_mb'].fillna(0)
            ax2.plot(self.state_data['datetime'], growth_data, 
                    label='Memory Growth', color='red', linewidth=1, alpha=0.7)
            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            
            # Add cumulative growth
            cumulative_growth = growth_data.cumsum()
            ax2_twin = ax2.twinx()
            ax2_twin.plot(self.state_data['datetime'], cumulative_growth, 
                         label='Cumulative Growth', color='blue', linewidth=2, alpha=0.8)
            ax2_twin.set_ylabel('Cumulative Growth (MB)', color='blue')
        
        ax2.set_title('Memory Growth Rate')
        ax2.set_xlabel('Time')
        ax2.set_ylabel('Growth per Step (MB)', color='red')
        ax2.grid(True, alpha=0.3)
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        # Plot 3: Memory vs Graph Size
        ax3 = axes[1, 0]
        if 'graph_size' in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
            ax3.scatter(self.state_data['graph_size'], self.state_data['physical_memory_mb'], 
                       alpha=0.6, s=30)
            
            # Add trend line
            valid_data = self.state_data[['graph_size', 'physical_memory_mb']].dropna()
            if len(valid_data) > 1:
                z = np.polyfit(valid_data['graph_size'], valid_data['physical_memory_mb'], 1)
                p = np.poly1d(z)
                ax3.plot(valid_data['graph_size'], p(valid_data['graph_size']), 
                        "r--", alpha=0.8, linewidth=2, label=f'Trend: y={z[0]:.4f}x+{z[1]:.2f}')
                ax3.legend()
        
        ax3.set_title('Memory vs Graph Size')
        ax3.set_xlabel('Graph Size (factors)')
        ax3.set_ylabel('Physical Memory (MB)')
        ax3.grid(True, alpha=0.3)
        
        # Plot 4: Memory efficiency over time
        ax4 = axes[1, 1]
        if 'total_factors' in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
            efficiency = self.state_data['physical_memory_mb'] / (self.state_data['total_factors'] + 1)
            ax4.plot(self.state_data['datetime'], efficiency, 
                    color='green', linewidth=2, alpha=0.8)
            
            # Add moving average
            window_size = min(10, len(efficiency) // 2)
            if window_size > 1:
                moving_avg = efficiency.rolling(window=window_size, center=True).mean()
                ax4.plot(self.state_data['datetime'], moving_avg, 
                        color='orange', linewidth=3, alpha=0.9, label=f'{window_size}-point Moving Avg')
                ax4.legend()
        
        ax4.set_title('Memory Efficiency (MB per Factor)')
        ax4.set_xlabel('Time')
        ax4.set_ylabel('Memory per Factor (MB)')
        ax4.grid(True, alpha=0.3)
        ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
        plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)
        
        plt.tight_layout()
        
        # Save plot
        output_path = self.output_dir / 'memory_timeline_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Memory timeline plot saved: {output_path}")
        self.generated_plots.append(output_path)
        plt.close()
    
    def plot_factor_memory_correlation(self):
        """Plot correlation between factors and memory usage"""
        if self.state_data is None:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Factor Count vs Memory Usage Analysis', fontsize=16, fontweight='bold')
        
        factor_types = ['total_gnss_pos_factors', 'total_gnss_vel_factors', 
                       'total_imu_factors', 'total_bias_factors']
        factor_names = ['GNSS Position', 'GNSS Velocity', 'IMU', 'Bias']
        
        for i, (factor_col, name) in enumerate(zip(factor_types, factor_names)):
            ax = axes[i//2, i%2]
            
            if factor_col in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
                valid_data = self.state_data[[factor_col, 'physical_memory_mb']].dropna()
                
                if len(valid_data) > 0:
                    ax.scatter(valid_data[factor_col], valid_data['physical_memory_mb'], 
                             alpha=0.6, s=40)
                    
                    # Add trend line and correlation
                    if len(valid_data) > 1:
                        correlation = np.corrcoef(valid_data[factor_col], 
                                                valid_data['physical_memory_mb'])[0,1]
                        z = np.polyfit(valid_data[factor_col], valid_data['physical_memory_mb'], 1)
                        p = np.poly1d(z)
                        ax.plot(valid_data[factor_col], p(valid_data[factor_col]), 
                               "r--", alpha=0.8, linewidth=2)
                        
                        ax.set_title(f'{name} Factors\n(Correlation: {correlation:.3f})')
                    else:
                        ax.set_title(f'{name} Factors')
                    
                    ax.set_xlabel(f'{name} Factor Count')
                    ax.set_ylabel('Physical Memory (MB)')
                    ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save plot
        output_path = self.output_dir / 'factor_memory_correlation.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Factor correlation plot saved: {output_path}")
        self.generated_plots.append(output_path)
        plt.close()
    
    def plot_performance_analysis(self):
        """Plot performance vs memory analysis"""
        if self.state_data is None:
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 10))  # Changed to 2x3 layout
        fig.suptitle('Performance vs Memory Analysis', fontsize=16, fontweight='bold')
        
        # Plot 1: Optimization time over time
        ax1 = axes[0, 0]
        if 'optimization_time_ms' in self.state_data.columns:
            ax1.plot(self.state_data['datetime'], self.state_data['optimization_time_ms'], 
                    color='purple', linewidth=2, alpha=0.8)
            ax1.set_title('Optimization Time Over Time')
            ax1.set_xlabel('Time')
            ax1.set_ylabel('Optimization Time (ms)')
            ax1.grid(True, alpha=0.3)
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
            plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # Plot 2: Memory vs Optimization time
        ax2 = axes[0, 1]
        if 'optimization_time_ms' in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
            valid_data = self.state_data[['optimization_time_ms', 'physical_memory_mb']].dropna()
            if len(valid_data) > 0:
                ax2.scatter(valid_data['physical_memory_mb'], valid_data['optimization_time_ms'], 
                           alpha=0.6, s=40)
                
                if len(valid_data) > 1:
                    correlation = np.corrcoef(valid_data['physical_memory_mb'], 
                                            valid_data['optimization_time_ms'])[0,1]
                    ax2.set_title(f'Memory vs Optimization Time\n(Correlation: {correlation:.3f})')
                else:
                    ax2.set_title('Memory vs Optimization Time')
                
                ax2.set_xlabel('Physical Memory (MB)')
                ax2.set_ylabel('Optimization Time (ms)')
                ax2.grid(True, alpha=0.3)
        
        # Plot 3: Optimization Time CDF (NEW)
        ax3 = axes[0, 2]
        if 'optimization_time_ms' in self.state_data.columns:
            opt_times = self.state_data['optimization_time_ms'].dropna()
            if len(opt_times) > 0:
                # Sort the data
                sorted_times = np.sort(opt_times)
                # Calculate CDF
                y_values = np.arange(1, len(sorted_times) + 1) / len(sorted_times)
                
                # Plot CDF
                ax3.plot(sorted_times, y_values, linewidth=2, color='darkred', alpha=0.8)
                ax3.fill_between(sorted_times, y_values, alpha=0.3, color='darkred')
                
                # Add key percentiles
                percentiles = [50, 95, 99]
                colors = ['orange', 'red', 'darkred']
                for p, color in zip(percentiles, colors):
                    percentile_value = np.percentile(sorted_times, p)
                    ax3.axvline(percentile_value, color=color, linestyle='--', alpha=0.8,
                               label=f'{p}th percentile: {percentile_value:.1f}ms')
                    ax3.axhline(p/100, color=color, linestyle='--', alpha=0.5)
                
                ax3.set_title('Optimization Time CDF')
                ax3.set_xlabel('Optimization Time (ms)')
                ax3.set_ylabel('Cumulative Probability')
                ax3.grid(True, alpha=0.3)
                ax3.legend(fontsize=8)
                ax3.set_ylim(0, 1)
                
                # Add statistics text
                mean_time = opt_times.mean()
                std_time = opt_times.std()
                ax3.text(0.05, 0.95, f'Mean: {mean_time:.1f}ms\nStd: {std_time:.1f}ms\nSamples: {len(opt_times)}',
                        transform=ax3.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        # Plot 4: High frequency pose count
        ax4 = axes[1, 0]
        if 'high_freq_pose_count' in self.state_data.columns:
            ax4.plot(self.state_data['datetime'], self.state_data['high_freq_pose_count'], 
                    color='orange', linewidth=2, alpha=0.8)
            ax4.set_title('High Frequency Pose Count Over Time')
            ax4.set_xlabel('Time')
            ax4.set_ylabel('High Freq Pose Count')
            ax4.grid(True, alpha=0.3)
            ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
            plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)
        
        # Plot 5: Keyframe count vs memory
        ax5 = axes[1, 1]
        if 'keyframe_count' in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
            ax5.plot(self.state_data['keyframe_count'], self.state_data['physical_memory_mb'], 
                    color='green', linewidth=2, alpha=0.8, marker='o', markersize=4)
            ax5.set_title('Memory vs Keyframe Count')
            ax5.set_xlabel('Keyframe Count')
            ax5.set_ylabel('Physical Memory (MB)')
            ax5.grid(True, alpha=0.3)
        
        # Plot 6: Optimization Time Histogram with Statistics
        ax6 = axes[1, 2]
        if 'optimization_time_ms' in self.state_data.columns:
            opt_times = self.state_data['optimization_time_ms'].dropna()
            if len(opt_times) > 0:
                # Create histogram
                n, bins, patches = ax6.hist(opt_times, bins=30, alpha=0.7, color='lightblue', 
                                          edgecolor='black', density=True)
                
                # Add statistical lines
                mean_time = opt_times.mean()
                median_time = opt_times.median()
                
                ax6.axvline(mean_time, color='red', linestyle='--', linewidth=2, 
                           label=f'Mean: {mean_time:.1f}ms')
                ax6.axvline(median_time, color='orange', linestyle='--', linewidth=2, 
                           label=f'Median: {median_time:.1f}ms')
                
                # Add fitted distribution curve if possible
                try:
                    # Fit a normal distribution
                    mu, sigma = stats.norm.fit(opt_times)
                    x = np.linspace(opt_times.min(), opt_times.max(), 100)
                    pdf = stats.norm.pdf(x, mu, sigma)
                    ax6.plot(x, pdf, 'g-', linewidth=2, alpha=0.8, 
                            label=f'Normal fit (μ={mu:.1f}, σ={sigma:.1f})')
                except Exception:
                    pass  # Skip if fitting fails
                
                ax6.set_title('Optimization Time Distribution')
                ax6.set_xlabel('Optimization Time (ms)')
                ax6.set_ylabel('Density')
                ax6.legend(fontsize=8)
                ax6.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save plot
        output_path = self.output_dir / 'performance_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Performance analysis plot saved: {output_path}")
        self.generated_plots.append(output_path)
        plt.close()
    
    def plot_memory_distribution(self):
        """Plot memory usage distribution and histograms"""
        if self.state_data is None:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Memory Usage Distribution Analysis', fontsize=16, fontweight='bold')
        
        # Plot 1: Physical memory histogram
        ax1 = axes[0, 0]
        if 'physical_memory_mb' in self.state_data.columns:
            data = self.state_data['physical_memory_mb'].dropna()
            if len(data) > 0:
                ax1.hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
                ax1.axvline(data.mean(), color='red', linestyle='--', linewidth=2, 
                           label=f'Mean: {data.mean():.2f} MB')
                ax1.axvline(data.median(), color='orange', linestyle='--', linewidth=2, 
                           label=f'Median: {data.median():.2f} MB')
                ax1.set_title('Physical Memory Distribution')
                ax1.set_xlabel('Physical Memory (MB)')
                ax1.set_ylabel('Frequency')
                ax1.legend()
                ax1.grid(True, alpha=0.3)
        
        # Plot 2: Memory growth histogram
        ax2 = axes[0, 1]
        if 'memory_growth_mb' in self.state_data.columns:
            growth_data = self.state_data['memory_growth_mb'].dropna()
            if len(growth_data) > 0:
                ax2.hist(growth_data, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
                ax2.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.8)
                ax2.axvline(growth_data.mean(), color='red', linestyle='--', linewidth=2, 
                           label=f'Mean: {growth_data.mean():.4f} MB')
                ax2.set_title('Memory Growth Distribution')
                ax2.set_xlabel('Memory Growth per Step (MB)')
                ax2.set_ylabel('Frequency')
                ax2.legend()
                ax2.grid(True, alpha=0.3)
        
        # Plot 3: Box plot of memory types
        ax3 = axes[1, 0]
        memory_data = []
        memory_labels = []
        
        for col, label in [('virtual_memory_mb', 'Virtual'), 
                          ('physical_memory_mb', 'Physical'), 
                          ('peak_memory_mb', 'Peak')]:
            if col in self.state_data.columns:
                data = self.state_data[col].dropna()
                if len(data) > 0:
                    memory_data.append(data)
                    memory_labels.append(label)
        
        if memory_data:
            ax3.boxplot(memory_data, labels=memory_labels)
            ax3.set_title('Memory Usage Box Plot')
            ax3.set_ylabel('Memory (MB)')
            ax3.grid(True, alpha=0.3)
        
        # Plot 4: Memory efficiency histogram
        ax4 = axes[1, 1]
        if 'total_factors' in self.state_data.columns and 'physical_memory_mb' in self.state_data.columns:
            valid_data = self.state_data[['total_factors', 'physical_memory_mb']].dropna()
            valid_data = valid_data[valid_data['total_factors'] > 0]
            
            if len(valid_data) > 0:
                efficiency = valid_data['physical_memory_mb'] / valid_data['total_factors']
                ax4.hist(efficiency, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
                ax4.axvline(efficiency.mean(), color='red', linestyle='--', linewidth=2, 
                           label=f'Mean: {efficiency.mean():.4f} MB/factor')
                ax4.set_title('Memory Efficiency Distribution')
                ax4.set_xlabel('Memory per Factor (MB)')
                ax4.set_ylabel('Frequency')
                ax4.legend()
                ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save plot
        output_path = self.output_dir / 'memory_distribution.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Memory distribution plot saved: {output_path}")
        self.generated_plots.append(output_path)
        plt.close()
    
    def generate_summary_report(self):
        """Generate a comprehensive summary report"""
        if self.state_data is None:
            return
        
        report_path = self.output_dir / 'memory_analysis_report.txt'
        
        with open(report_path, 'w') as f:
            f.write("GNSS-IMU FUSION MEMORY ANALYSIS REPORT\n")
            f.write("="*50 + "\n\n")
            
            # Basic info
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total Records: {len(self.state_data)}\n")
            
            if 'datetime' in self.state_data.columns:
                duration = (self.state_data['datetime'].max() - self.state_data['datetime'].min()).total_seconds()
                f.write(f"Data Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\n")
            
            f.write("\n" + "-"*50 + "\n")
            f.write("MEMORY USAGE SUMMARY\n")
            f.write("-"*50 + "\n")
            
            # Memory statistics
            for col, name in [('virtual_memory_mb', 'Virtual Memory'), 
                             ('physical_memory_mb', 'Physical Memory'), 
                             ('peak_memory_mb', 'Peak Memory')]:
                if col in self.state_data.columns:
                    data = self.state_data[col].dropna()
                    if len(data) > 0:
                        f.write(f"\n{name}:\n")
                        f.write(f"  Minimum: {data.min():.2f} MB\n")
                        f.write(f"  Maximum: {data.max():.2f} MB\n")
                        f.write(f"  Average: {data.mean():.2f} MB\n")
                        f.write(f"  Standard Deviation: {data.std():.2f} MB\n")
                        f.write(f"  Growth: {data.max() - data.min():.2f} MB\n")
            
            # Factor analysis
            if 'total_factors' in self.state_data.columns:
                f.write(f"\n" + "-"*50 + "\n")
                f.write("FACTOR ANALYSIS\n")
                f.write("-"*50 + "\n")
                
                final_row = self.state_data.iloc[-1]
                factor_cols = ['total_gnss_pos_factors', 'total_gnss_vel_factors', 
                              'total_imu_factors', 'total_bias_factors', 'total_prior_factors']
                
                for col in factor_cols:
                    if col in self.state_data.columns:
                        count = final_row[col]
                        f.write(f"  {col.replace('_', ' ').title()}: {count}\n")
                
                total_factors = final_row['total_factors']
                final_memory = final_row['physical_memory_mb']
                efficiency = final_memory / total_factors if total_factors > 0 else 0
                
                f.write(f"\n  Total Factors: {total_factors}\n")
                f.write(f"  Memory Efficiency: {efficiency:.4f} MB per factor\n")
            
            # Performance analysis
            if 'optimization_time_ms' in self.state_data.columns:
                f.write(f"\n" + "-"*50 + "\n")
                f.write("PERFORMANCE ANALYSIS\n")
                f.write("-"*50 + "\n")
                
                opt_times = self.state_data['optimization_time_ms'].dropna()
                if len(opt_times) > 0:
                    f.write(f"  Average Optimization Time: {opt_times.mean():.2f} ms\n")
                    f.write(f"  Max Optimization Time: {opt_times.max():.2f} ms\n")
                    f.write(f"  Min Optimization Time: {opt_times.min():.2f} ms\n")
                    
                    # Correlation with memory
                    if 'physical_memory_mb' in self.state_data.columns:
                        valid_pairs = self.state_data[['optimization_time_ms', 'physical_memory_mb']].dropna()
                        if len(valid_pairs) > 1:
                            corr = np.corrcoef(valid_pairs['optimization_time_ms'], 
                                             valid_pairs['physical_memory_mb'])[0,1]
                            f.write(f"  Memory-Performance Correlation: {corr:.3f}\n")
            
            # Recommendations
            f.write(f"\n" + "-"*50 + "\n")
            f.write("RECOMMENDATIONS\n")
            f.write("-"*50 + "\n")
            
            if 'memory_growth_mb' in self.state_data.columns:
                growth_data = self.state_data['memory_growth_mb'].dropna()
                avg_growth = growth_data.mean()
                
                if avg_growth > 0.1:
                    f.write("⚠️  High memory growth detected. Consider:\n")
                    f.write("   - Implementing periodic memory cleanup\n")
                    f.write("   - Reducing factor graph size\n")
                    f.write("   - Using sliding window optimization\n")
                elif avg_growth < -0.1:
                    f.write("✅ Memory usage is well controlled\n")
                else:
                    f.write("✅ Memory growth is within acceptable range\n")
        
        print(f"Summary report generated: {report_path}")
    
    def display_plots(self):
        """Display generated plots using system default image viewer"""
        if not self.show_plots or not self.generated_plots:
            print("Plot display disabled or no plots generated.")
            return
        
        print(f"\nDisplaying {len(self.generated_plots)} generated plots...")
        
        # Try different image viewers in order of preference
        viewers = ['eog', 'feh', 'display', 'xdg-open', 'gnome-open', 'kde-open']
        
        viewer_cmd = None
        for viewer in viewers:
            try:
                # Check if viewer is available
                subprocess.run(['which', viewer], 
                             stdout=subprocess.DEVNULL, 
                             stderr=subprocess.DEVNULL, 
                             check=True)
                viewer_cmd = viewer
                break
            except subprocess.CalledProcessError:
                continue
        
        if not viewer_cmd:
            print("No suitable image viewer found. Please install one of:", ', '.join(viewers))
            print("Or manually open the plot files:")
            for plot_path in self.generated_plots:
                print(f"  - {plot_path}")
            return
        
        print(f"Using image viewer: {viewer_cmd}")
        
        # Display each plot
        for i, plot_path in enumerate(self.generated_plots, 1):
            print(f"Displaying plot {i}/{len(self.generated_plots)}: {plot_path.name}")
            try:
                if viewer_cmd == 'feh':
                    # feh supports multiple images
                    subprocess.run([viewer_cmd, '--scale-down', '--auto-zoom', str(plot_path)], 
                                 stdout=subprocess.DEVNULL, 
                                 stderr=subprocess.DEVNULL)
                elif viewer_cmd in ['eog', 'display']:
                    # These viewers can handle single images well
                    subprocess.run([viewer_cmd, str(plot_path)], 
                                 stdout=subprocess.DEVNULL, 
                                 stderr=subprocess.DEVNULL)
                else:
                    # Generic viewers
                    subprocess.run([viewer_cmd, str(plot_path)], 
                                 stdout=subprocess.DEVNULL, 
                                 stderr=subprocess.DEVNULL)
                
                # Small delay between images
                import time
                time.sleep(0.5)
                
            except subprocess.CalledProcessError as e:
                print(f"Error displaying {plot_path.name}: {e}")
            except Exception as e:
                print(f"Unexpected error displaying {plot_path.name}: {e}")
    
    def display_all_plots_together(self):
        """Display all plots together using a multi-image viewer"""
        if not self.show_plots or not self.generated_plots:
            return
        
        print(f"\nAttempting to display all {len(self.generated_plots)} plots together...")
        
        # Try viewers that support multiple images
        multi_viewers = [
            (['feh', '--scale-down', '--auto-zoom'] + [str(p) for p in self.generated_plots], 'feh'),
            (['eog'] + [str(p) for p in self.generated_plots], 'eog (Eye of GNOME)'),
            (['gwenview'] + [str(p) for p in self.generated_plots], 'gwenview (KDE)'),
        ]
        
        for cmd_args, viewer_name in multi_viewers:
            try:
                # Check if viewer is available
                subprocess.run(['which', cmd_args[0]], 
                             stdout=subprocess.DEVNULL, 
                             stderr=subprocess.DEVNULL, 
                             check=True)
                
                print(f"Opening all plots with {viewer_name}...")
                subprocess.run(cmd_args, 
                             stdout=subprocess.DEVNULL, 
                             stderr=subprocess.DEVNULL,
                             timeout=5)  # Don't wait too long
                return
                
            except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
                continue
        
        # Fallback to displaying one by one
        print("Multi-image viewer not available, displaying plots individually...")
        self.display_plots()
    
    def open_output_directory(self):
        """Open the output directory in file manager"""
        if not self.show_plots:
            return
            
        print(f"\nOpening output directory: {self.output_dir}")
        
        # Try different file managers
        file_managers = ['nautilus', 'dolphin', 'thunar', 'pcmanfm', 'xdg-open']
        
        for fm in file_managers:
            try:
                subprocess.run(['which', fm], 
                             stdout=subprocess.DEVNULL, 
                             stderr=subprocess.DEVNULL, 
                             check=True)
                
                subprocess.run([fm, str(self.output_dir)], 
                             stdout=subprocess.DEVNULL, 
                             stderr=subprocess.DEVNULL,
                             timeout=3)
                print(f"Opened directory with {fm}")
                return
                
            except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
                continue
        
        print("Could not open file manager. Directory location:")
        print(f"  {self.output_dir}")

    def run_complete_analysis(self):
        """Run complete memory analysis"""
        print("Starting complete memory analysis...")
        
        if not self.load_csv_files():
            print("Failed to load data files. Analysis aborted.")
            return
        
        # Generate statistics
        self.analyze_memory_statistics()
        
        # Generate all plots
        self.plot_memory_timeline()
        self.plot_factor_memory_correlation()
        self.plot_performance_analysis()
        self.plot_memory_distribution()
        
        # Generate summary report
        self.generate_summary_report()
        
        print(f"\nComplete analysis finished!")
        print(f"All outputs saved to: {self.output_dir}")
        print(f"Generated files:")
        for file in self.output_dir.glob("*"):
            print(f"  - {file.name}")
        
        # Display results if requested
        if self.show_plots:
            print("\n" + "="*60)
            print("DISPLAYING ANALYSIS RESULTS")
            print("="*60)
            
            # Try to display all plots together first
            self.display_all_plots_together()
            
            # Open output directory
            self.open_output_directory()
            
            # Show summary
            report_path = self.output_dir / 'memory_analysis_report.txt'
            if report_path.exists():
                print(f"\nSummary report location: {report_path}")
                try:
                    with open(report_path, 'r') as f:
                        content = f.read()
                        # Show first few lines of the report
                        lines = content.split('\n')[:20]
                        print("\nReport Preview:")
                        print("-" * 40)
                        for line in lines:
                            print(line)
                        if len(content.split('\n')) > 20:
                            print("... (see full report in file)")
                        print("-" * 40)
                except Exception as e:
                    print(f"Could not preview report: {e}")


def main():
    """Main function with command line interface"""
    parser = argparse.ArgumentParser(description='GNSS-IMU Fusion Memory Analysis Tool')
    parser.add_argument('--input_dir', type=str, default='/home/jay/batch_board/output',
                       help='Directory containing CSV files (default: /home/jay/batch_board/output)')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='Output directory for plots and reports (default: script directory/plots)')
    parser.add_argument('--trajectory_csv', type=str, default=None,
                       help='Direct path to trajectory CSV file (overrides directory search)')
    parser.add_argument('--state_csv', type=str, default=None,
                       help='Direct path to state CSV file (overrides directory search)')
    parser.add_argument('--no-display', action='store_true',
                       help='Disable automatic display of plots and results')
    
    args = parser.parse_args()
    
    # Create analyzer with specified parameters
    analyzer = MemoryAnalyzer(
        input_dir=args.input_dir, 
        output_dir=args.output_dir,
        trajectory_csv=args.trajectory_csv,
        state_csv=args.state_csv,
        show_plots=not args.no_display
    )
    analyzer.run_complete_analysis()


if __name__ == "__main__":
    main()
